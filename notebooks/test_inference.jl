#= Example script for the inference of a single bending power spectral density using Pioran and ultranest (python package).

run with:

julia single.jl data.txt

where `data.txt` is a file containing the time series data. The file should have three columns: time, flux, flux error. 
The script will create a directory `inference` containing the results of the inference.

If you have MPI installed, you may want to run the script in parallel, using the following command:

mpirun -n 4 julia single.jl data.txt

where `-n 4` is the number of processes to use.

=#

# load MPI and initialise
using MPI
MPI.Init()
comm = MPI.COMM_WORLD

using Meiran
using Tonari
using Distributions
using Random
using DelimitedFiles
using Statistics
using PyCall
# load the python package ultranest
ultranest = pyimport("ultranest")
# define the random number generator
rng = MersenneTwister(123)

# get the filename from the command line
filename = ARGS[1]
fname = replace(split(filename, "/")[end], ".txt" => "_single")
dir = "inference/" * fname
plot_path = dir * "/plots/"

# Load the data and extract a subset for the analysis
A = readdlm(filename, comments = true, comment_char = '#')
t, xâ‚, xâ‚‚, Ïƒ_xâ‚, Ïƒ_xâ‚‚ = A[:, 1], A[:, 2], A[:, 3], A[:, 4], A[:, 5]

xâ‚ .-= mean(xâ‚)
xâ‚‚ .-= mean(xâ‚‚)
# Frequency range for the approx and the prior
f_min, f_max = 1 / (t[end] - t[1]), 1 / minimum(diff(t)) / 2

# options for the approximation
S_low, S_high = 5, 5
f0, fM = 1 / t[end] / S_low, 1 / (2 * minimum(diff(t))) * S_high
min_f_b, max_f_b = f0 * 4.0, fM / 4.0

n_components = 20
model = SingleBendingPowerLaw

function loglikelihood(xâ‚::Vector{Float64}, xâ‚‚::Vector{Float64}, tâ‚::Vector{Float64}, tâ‚‚::Vector{Float64}, Ïƒ_xâ‚::Vector{Float64}, Ïƒ_xâ‚‚::Vector{Float64}, params::Vector{Float64})
	Î¸â‚, Î¸â‚‚, Î”Ï„ = params[1:3], params[4:6], params[7]

	# Define power spectral density function
	ğ“Ÿâ‚ = model(Î¸â‚...)
	ğ“Ÿâ‚‚ = model(Î¸â‚‚...)
	Î”Ï• = ConstantTimeLag(Î”Ï„)
	ğ“’â‚â‚‚ = CrossSpectralDensity(ğ“Ÿâ‚, ğ“Ÿâ‚‚, Î”Ï•)

	return log_likelihood(ğ“’â‚â‚‚, tâ‚, tâ‚‚, xâ‚, xâ‚‚, Ïƒ_xâ‚, Ïƒ_xâ‚‚, f0, fM, n_components)
end
logl(pars::Vector{Float64}) = loglikelihood(xâ‚, xâ‚‚, t, t, Ïƒ_xâ‚ .^ 2, Ïƒ_xâ‚‚ .^ 2, pars)

# # Priors
function prior_transform(cube)
	Î±â‚Â¹ = quantile(Uniform(0.0, 1.5), cube[1])
	fâ‚Â¹ = quantile(LogUniform(min_f_b, max_f_b), cube[2])
	Î±â‚‚Â¹ = quantile(Uniform(1.5, 4.0), cube[3])
	Î±â‚Â² = quantile(Uniform(0.0, 1.5), cube[4])
	fâ‚Â² = quantile(LogUniform(min_f_b, max_f_b), cube[5])
	Î±â‚‚Â² = quantile(Uniform(1.5, 4.0), cube[6])
	Î”Ï„ = quantile(Uniform(-t[end] / 4, t[end] / 4), cube[7])
	return [Î±â‚Â¹, fâ‚Â¹, Î±â‚‚Â¹, Î±â‚Â², fâ‚Â², Î±â‚‚Â², Î”Ï„]
end
paramnames = ["Î±â‚Â¹", "fâ‚Â¹", "Î±â‚‚Â¹", "Î±â‚Â²", "fâ‚Â²", "Î±â‚‚Â²", "Î”Ï„"]

# println("Hello world, I am $(MPI.Comm_rank(comm)) of $(MPI.Comm_size(comm))")

# println("Running sampler...")
sampler = ultranest.ReactiveNestedSampler(paramnames, logl, resume = true, transform = prior_transform, log_dir = dir, vectorized = false)
results = sampler.run()
sampler.print_results()
sampler.plot()
